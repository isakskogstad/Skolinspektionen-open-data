name: Nightly Index Update

on:
  schedule:
    # Run at 02:00 UTC = 03:00 CET (Swedish time)
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      max_pages:
        description: 'Maximum pages to scrape'
        required: false
        default: '20'
        type: string

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout main (code)
        uses: actions/checkout@v4
        with:
          ref: main

      - name: Checkout data branch into data/
        uses: actions/checkout@v4
        with:
          ref: data
          path: data-branch
        continue-on-error: true

      - name: Create data directory if needed
        run: |
          mkdir -p data/api
          if [ -d "data-branch" ]; then
            cp -r data-branch/* data/ 2>/dev/null || true
          fi

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e "."

      - name: Run scraper
        env:
          SI_MAX_PAGES_PER_SCRAPE: ${{ github.event.inputs.max_pages || '20' }}
        run: |
          si-scrape
          echo "Scraping completed at $(date -u +"%Y-%m-%dT%H:%M:%SZ")"

      - name: Check for changes
        id: changes
        run: |
          if [ -f "data/api/index.json" ]; then
            echo "has_data=true" >> $GITHUB_OUTPUT
            echo "Index file found"
            cat data/api/index.json | head -20
          else
            echo "has_data=false" >> $GITHUB_OUTPUT
            echo "No index file generated"
          fi

      - name: Push to data branch
        if: steps.changes.outputs.has_data == 'true'
        run: |
          cd data

          # Initialize git if needed
          git init 2>/dev/null || true
          git remote add origin https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git 2>/dev/null || true

          # Fetch and setup tracking
          git fetch origin data 2>/dev/null || true
          git checkout -B data

          # Configure git
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # Add and commit
          git add -A

          # Check if there are changes
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Update index $(date -u +%Y-%m-%d)"
            git push origin data --force
            echo "Data pushed to data branch"
          fi

      - name: Summary
        run: |
          echo "## Scrape Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f "data/api/index.json" ]; then
            echo "✅ Index updated successfully" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Counts" >> $GITHUB_STEP_SUMMARY
            echo '```json' >> $GITHUB_STEP_SUMMARY
            cat data/api/index.json | python3 -c "import sys,json; d=json.load(sys.stdin); print(json.dumps({'publications': len(d.get('publications',[])), 'press_releases': len(d.get('press_releases',[])), 'statistics_files': len(d.get('statistics_files',[])), 'last_updated': d.get('last_updated')}, indent=2))"
            echo '```' >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ No index generated" >> $GITHUB_STEP_SUMMARY
          fi
